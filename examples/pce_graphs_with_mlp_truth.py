"""
An advanced example comparing different PCE-based model architectures against
a "true" process generated by a neural network.

This script demonstrates the use of the powerful PCEScaleShiftModel.

It performs the following steps:
1. Defines a "true" 3-fidelity data-generating process using MLPs in a
   hierarchical graph structure (1 -> 2 -> 3).
2. Generates training and testing data from this true process.
3. Defines two candidate graph architectures: Peer and Hierarchical.
4. For each architecture, trains models using 1st, 2nd, 3rd, and 4th degree
   Polynomial Chaos Expansions (PCEs) with the PCEScaleShiftModel.
5. Creates a single, comprehensive 2x5 plot that visualizes each graph
   structure and the prediction performance for each PCE degree.
"""
import os
from functools import partial

import jax
import jax.numpy as jnp
import networkx as nx
import optax
from jax import tree_util
from matplotlib import pyplot as plt

from mfnets_surrogates import (
    MFNetJax,
    MLPModel,
    PCEScaleShiftModel, # Import the new model
    init_mlp_params,
    init_mlp_enhancement_model,
    init_pce_model,
    init_pce_scale_shift_model, # Import its initializer
    mse_loss_graph,
)

# --- Plotting and Graph Helpers ---

def plot_graph_on_ax(ax, graph: nx.DiGraph, title: str):
    """Draw a NetworkX graph on a given Matplotlib Axes object."""
    pos = nx.spring_layout(graph, seed=42)
    nx.draw(
        graph,
        pos,
        ax=ax,
        with_labels=True,
        node_size=2000,
        node_color="#a2d2ff",
        font_size=14,
        font_weight="bold",
        arrowsize=20,
    )
    ax.set_title(title, fontsize=16)

def plot_predictions_on_ax(ax, y_true, y_pred, mse: float, title: str):
    """Draw a predicted vs. actual scatter plot on a given Axes object."""
    ax.scatter(y_true, y_pred, alpha=0.6)
    ax.plot(
        [y_true.min(), y_true.max()],
        [y_true.min(), y_true.max()],
        "r--",
        lw=2,
    )
    ax.text(
        0.95,
        0.05,
        f"Test MSE: {mse:.4f}",
        verticalalignment="bottom",
        horizontalalignment="right",
        transform=ax.transAxes,
        fontsize=12,
        bbox={"boxstyle": "round,pad=0.5", "facecolor": "wheat", "alpha": 0.5},
    )
    ax.set_xlabel("True Values", fontsize=10)
    ax.set_ylabel("Predicted Values", fontsize=10)
    ax.set_title(title, fontsize=14)
    ax.grid(True, linestyle="--", alpha=0.6)
    ax.set_aspect("equal", adjustable="box")

def train_graph(mfnet: MFNetJax, x_train, y_train, num_steps=15000):
    """A helper function to run the Optax training loop for a given graph."""
    target_nodes = tuple(sorted(mfnet.graph.nodes))
    params, treedef = tree_util.tree_flatten(mfnet)
    optimizer = optax.adam(learning_rate=5e-3)
    opt_state = optimizer.init(params)

    def _calculate_loss(current_params, x, y):
        """Helper for loss calculation, compatible with jax.grad."""
        model = treedef.unflatten(current_params)
        return mse_loss_graph(model, target_nodes, x, y)

    @jax.jit
    def step(p, opt_s, x, y):
        grads = jax.grad(_calculate_loss)(p, x, y)
        updates, opt_s = optimizer.update(grads, opt_s)
        p = optax.apply_updates(p, updates)
        return p, opt_s

    for _ in range(num_steps):
        params, opt_state = step(params, opt_state, x_train, y_train)

    return treedef.unflatten(params)


def _create_peer_pce_graph(key, d_in, d_out, degree) -> MFNetJax:
    """Builds the Peer graph (1->3, 2->3) with PCEScaleShiftModels."""
    key1, key2, key3 = jax.random.split(key, 3)
    graph = nx.DiGraph([(1, 3), (2, 3)])

    m1 = init_pce_model(key1, d_in, d_out, degree)
    m2 = init_pce_model(key2, d_in, d_out, degree)
    # The parent dimension is d_out * 2 because it receives from two parents
    m3 = init_pce_scale_shift_model(key3, d_in, d_out * 2, d_out, degree)

    graph.add_node(1, func=m1)
    graph.add_node(2, func=m2)
    graph.add_node(3, func=m3)
    return MFNetJax(graph)

def _create_hierarchical_pce_graph(key, d_in, d_out, degree) -> MFNetJax:
    """Builds the Hierarchical graph (1->2->3) with PCEScaleShiftModels."""
    key1, key2, key3 = jax.random.split(key, 3)
    graph = nx.DiGraph([(1, 2), (2, 3)])

    m1 = init_pce_model(key1, d_in, d_out, degree)
    m2 = init_pce_scale_shift_model(key2, d_in, d_out, d_out, degree)
    m3 = init_pce_scale_shift_model(key3, d_in, d_out, d_out, degree)

    graph.add_node(1, func=m1)
    graph.add_node(2, func=m2)
    graph.add_node(3, func=m3)
    return MFNetJax(graph)

# --- Main Experiment ---

def main():
    """Run the PCE graph comparison experiment."""
    key = jax.random.PRNGKey(0)
    d_in, d_out = 1, 1
    os.makedirs("plots", exist_ok=True)

    # 1. Define a "True" Model using MLPs
    print("--- 1. Generating data from a 'true' MLP-based model ---")
    key, m1_key, m2_key, m3_key = jax.random.split(key, 4)
    true_m1 = MLPModel(init_mlp_params(m1_key, [d_in, 16, d_out]), jax.nn.tanh)
    true_m2 = init_mlp_enhancement_model(m2_key, [d_in + d_out, 16, d_out], jax.nn.tanh)
    true_m3 = init_mlp_enhancement_model(m3_key, [d_in + d_out, 16, d_out], jax.nn.tanh)

    true_graph_struct = nx.DiGraph([(1, 2), (2, 3)])
    true_graph_struct.add_node(1, func=true_m1)
    true_graph_struct.add_node(2, func=true_m2)
    true_graph_struct.add_node(3, func=true_m3)
    true_mfnet = MFNetJax(true_graph_struct)

    # Generate and split data
    x_all = jnp.linspace(-2, 2, 400).reshape(-1, d_in)
    y_all = true_mfnet.run((1, 2, 3), x_all)
    train_indices = jax.random.permutation(jax.random.PRNGKey(42), 400)[:200]
    test_indices = jnp.setdiff1d(jnp.arange(400), train_indices)

    x_train, x_test = x_all[train_indices], x_all[test_indices]
    y_train = tuple(y[train_indices] for y in y_all)
    y_test = tuple(y[test_indices] for y in y_all)
    y_true_hf = y_test[2]

    # Setup for the combined plot
    fig, axes = plt.subplots(2, 5, figsize=(28, 11), dpi=120)
    fig.suptitle("PCE Scale-Shift Model Comparison", fontsize=24)

    graph_builders = {
        "Peer": (_create_peer_pce_graph, axes[0, :]),
        "Hierarchical": (_create_hierarchical_pce_graph, axes[1, :]),
    }

    # 2. Loop through experiments
    for name, (builder_fn, ax_row) in graph_builders.items():
        print(f"\n--- 2. Training {name} Models ---")
        # Use the graph from the first model for plotting structure
        temp_graph = builder_fn(jax.random.PRNGKey(0), d_in, d_out, 1)
        plot_graph_on_ax(ax_row[0], temp_graph.graph, f"{name} Graph Structure")

        for degree in [1, 2, 3, 4]:
            print(f"  Training with PCE Degree: {degree}...")
            key, pce_key = jax.random.split(key)
            mfnet = builder_fn(pce_key, d_in, d_out, degree)

            mfnet_trained = train_graph(mfnet, x_train, y_train)

            (y_pred,) = mfnet_trained.run((3,), x_test)
            test_mse = jnp.mean((y_true_hf - y_pred) ** 2)
            plot_predictions_on_ax(
                ax_row[degree], y_true_hf, y_pred, test_mse, f"PCE Degree {degree}"
            )

    # Finalize and save the plot
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    save_path = "plots/pce_scale_shift_comparison.png"
    fig.savefig(save_path)
    plt.close(fig)
    print(f"\nExperiment complete. Check '{save_path}' for results.")

if __name__ == "__main__":
    main()
